#summary Crash course on installing and using EARS
#labels manual

=Installing EARS=

==Requirements and prerequisites==

The sources have only two hard dependencies: the [http://sourceforge.net/projects/lemur/ Lemur toolkit] and the STL (which comes with all sane C++ compilers).

===Installing the Lemur toolkit===
See the [http://sourceforge.net/apps/trac/lemur/wiki/Compiling%20and%20Installing Compiling and Installing] section on the [http://sourceforge.net/apps/trac/lemur/wiki Lemur Toolkit and Indri Search Engine Wiki].

Note: EARS has been tested with the following versions of the Lemur toolkit: 4.3, 4.4, 4.7, 4.8, 4.9, 4.10

==Installing and compiling EARS==
  # download and extract EARS
  # open `Makefile` and set the value of the `Lemur_dir` variable according to your local settings
  # The build is fairly conventional. Go to the EARS directory, and type `make`
    * If you need to re-compile it for any reason, you may want to issue `make clean` and then `make` 

=Using EARS=

Usage will be demonstrated on the [ExampleDataSet "ILPS Abstracts" data set], shipped with the EARS distribution. 

==Indexing the collection==
The document collection needs to be indexed using the Lemur toolkit.

  # Change to the `EARS` directory<br>_This step is crucial as paths are set relative to this directory. Alternatively, you may edit the config files and change the paths to absolute ones._
  # Execute either of the two:
    * `{Lemur_dir}/bin/IndriBuildIndex examples/ilps_abstracts/conf/IndriBuildIndex.conf examples/ilps_abstracts/stopwords/stopwords.indri` for building an Indri index (preferred)
    * `{Lemur_dir}/bin/BuildIndex examples/ilps_abstracts/conf/BuildIndex.conf` for building a !KeyFile index,
where `{Lemur_dir}` is the location of your Lemur installation.

More details about the indexing process and the differences between index types are given on [http://sourceforge.net/apps/trac/lemur/wiki/Building%20Indexes this page].

==Finding and profiling entities==
EARS can help you in two entity related tasks:
  * *finding entities* is about retrieving entities for a query topic (_"Which entities are associated with the topic?"_). In our example, we rank people with respect to their expertise given a particular topical area. Therefore, for each query, a ranked list of entities (names) is returned. 
  * *entity profiling* is the other way around: for each entity we return topics (_"Which topics are associated with the entity?"_) In our example, topics are ranked according to the person's proficiency in each. 

Learn more about the tasks and the association finding models [Models here].

===Syntax===
The syntax of the `ears` program is the following:
`ears <command> <paramfile> [debug_level]`

Where
  * `<command>` is either `ef` (for entity finding) or `ep` (for entity profiling)
  * `<paramfile>` is a parameter file (see [Parameters this page] for the description of possible parameters)
  * `debug_level` (optionally) is the reporting level (see below and [Logging this page])

===Parameter files===
There are sample parameter files for the two baseline models in the `examples/ilps_abstracts/conf` directory: `ears_model1.conf` and `ears_model2.conf` for Models 1 and 2, respectively. 
  * If you indexed the collection using a !KeyFile index, you need to edit these files, and<br>replace the line `<index>examples/ilps_abstracts/index</index>` <br>with `<index>examples/ilps_abstracts/index/index.key</index>`

===Example usage===
_All examples are executed from the EARS directory_

Finding experts using Model 1:
{{{
ears ef examples/ilps_abstracts/conf/ears_model1.conf
}}}

The output will look like:
{{{
Entity and Association Retrieval System (EARS) v0.8 (2009-03-30)
Copyright (c) 2005-2009, Krisztian Balog

Loading index 'examples/ilps_abstracts/index'
Loading Entity-Document associations 'examples/ilps_abstracts/data/associations.list'
Loading queries 'examples/ilps_abstracts/data/queries.ldf'
Initializing Model 1
Estimating smoothing parameter
Calculating topic-entity associations
Model 1 completed
Writing output to 'examples/ilps_abstracts/output/model1.out'
Over and out
}}}

The debug levels can be used to see what is actually happening.
E.g., using `debug`
{{{
ears ef examples/ilps_abstracts/conf/ears_model1.conf debug
}}}
will help you to follow the process of the computation:
{{{
Estimating smoothing parameter
  Parameter beta is set to 426.557
Calculating topic-entity associations
  Constructing collection Language Model
  Caching collection probabilities
  Entity #1/61 (K_Balog)
  Entity #2/61 (M_Rijke)
  Entity #3/61 (W_Weerkamp)
}}}

Using `debugall` will include even more details, e.g., how the scores are computed:
{{{
  Entity #1/61 (K_Balog)
    Creating model based on 9 associated documents
    Scoring queries
      Query #1/10 ('q-01')
        log p(q|e) = 
          + p('information'|q) [0.333333] * log( p(t|e) [0.00336702] )
          + p('model'|q) [0.333333] * log( p(t|e) [0.00554641] )
          + p('retrieval'|q) [0.333333] * log( p(t|e) [0.0102995] )
          = -5.15466
        p(q|e) = 0.00577242
      Query #2/10 ('q-02')
        log p(q|e) = 
          + p('enterprise'|q) [0.333333] * log( p(t|e) [0.00507137] )
          + p('expert'|q) [0.333333] * log( p(t|e) [0.00764664] )
          + p('finding'|q) [0.333333] * log( p(t|e) [0.00974633] )
          = -4.9295
}}}

On the other end of the spectrum, you may use `warning` or `error` as the `debug_level` to report only warnings and errors, respectively.